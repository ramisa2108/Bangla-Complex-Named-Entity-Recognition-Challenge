{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sbnltk\n!pip install simpletransformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-21T08:46:38.505622Z","iopub.execute_input":"2023-01-21T08:46:38.506084Z","iopub.status.idle":"2023-01-21T08:47:46.092558Z","shell.execute_reply.started":"2023-01-21T08:46:38.506044Z","shell.execute_reply":"2023-01-21T08:47:46.091129Z"},"trusted":true},"execution_count":114,"outputs":[{"name":"stdout","text":"Collecting sbnltk\n  Downloading sbnltk-1.0.7.tar.gz (28 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting gdown>=3.12.2\n  Downloading gdown-4.6.0-py3-none-any.whl (14 kB)\nCollecting google_trans_new>=1.1.9\n  Downloading google_trans_new-1.1.9-py3-none-any.whl (9.2 kB)\nRequirement already satisfied: pandas>=1.2.2 in /opt/conda/lib/python3.7/site-packages (from sbnltk) (1.3.5)\nCollecting scikit-learn==0.22.2.post1\n  Downloading scikit_learn-0.22.2.post1-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: transformers>=4.3.2 in /opt/conda/lib/python3.7/site-packages (from sbnltk) (4.20.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from sbnltk) (1.11.0+cpu)\nRequirement already satisfied: tensorflow>=2.4.1 in /opt/conda/lib/python3.7/site-packages (from sbnltk) (2.6.4)\nRequirement already satisfied: sklearn_crfsuite>=0.3.6 in /opt/conda/lib/python3.7/site-packages (from sbnltk) (0.3.6)\nCollecting pytorch_pretrained_bert>=0.6.2\n  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting sentence_transformers\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn==0.22.2.post1->sbnltk) (1.0.1)\nRequirement already satisfied: numpy>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn==0.22.2.post1->sbnltk) (1.21.6)\nRequirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn==0.22.2.post1->sbnltk) (1.7.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gdown>=3.12.2->sbnltk) (4.64.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from gdown>=3.12.2->sbnltk) (4.11.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.7/site-packages (from gdown>=3.12.2->sbnltk) (2.28.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown>=3.12.2->sbnltk) (1.15.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from gdown>=3.12.2->sbnltk) (3.7.1)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.2.2->sbnltk) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.2.2->sbnltk) (2022.1)\nRequirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from pytorch_pretrained_bert>=0.6.2->sbnltk) (2021.11.10)\nRequirement already satisfied: boto3 in /opt/conda/lib/python3.7/site-packages (from pytorch_pretrained_bert>=0.6.2->sbnltk) (1.26.43)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from sklearn_crfsuite>=0.3.6->sbnltk) (0.9.0)\nRequirement already satisfied: python-crfsuite>=0.8.3 in /opt/conda/lib/python3.7/site-packages (from sklearn_crfsuite>=0.3.6->sbnltk) (0.9.8)\nRequirement already satisfied: tensorboard<2.7,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.1->sbnltk) (2.6.0)\nRequirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.1->sbnltk) (0.2.0)\nRequirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.1->sbnltk) (1.12.1)\nRequirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.1->sbnltk) (1.6.3)\nRequirement already satisfied: gast==0.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.1->sbnltk) (0.4.0)\nRequirement already satisfied: clang~=5.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.1->sbnltk) (5.0)\nRequirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.1->sbnltk) (3.3.0)\nRequirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.1->sbnltk) (1.12)\nCollecting numpy>=1.11.0\n  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.1->sbnltk) (1.1.2)\nCollecting typing-extensions<3.11,>=3.7\n  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\nRequirement already satisfied: keras<2.7,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.1->sbnltk) (2.6.0)\nRequirement already satisfied: grpcio<2.0,>=1.37.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.1->sbnltk) (1.47.0)\nRequirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.1->sbnltk) (1.1.0)\nRequirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.1->sbnltk) (2.6.0)\nRequirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.1->sbnltk) (0.37.1)\nCollecting h5py~=3.1.0\n  Downloading h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.1->sbnltk) (0.15.0)\nRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.1->sbnltk) (3.20.3)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.3.2->sbnltk) (0.10.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.3.2->sbnltk) (22.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers>=4.3.2->sbnltk) (4.13.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.3.2->sbnltk) (0.12.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.3.2->sbnltk) (6.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from sentence_transformers->sbnltk) (0.12.0+cpu)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence_transformers->sbnltk) (3.8.1)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from sentence_transformers->sbnltk) (0.1.97)\nRequirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py~=3.1.0->tensorflow>=2.4.1->sbnltk) (1.5.2)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow>=2.4.1->sbnltk) (1.35.0)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow>=2.4.1->sbnltk) (1.8.1)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow>=2.4.1->sbnltk) (0.6.1)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow>=2.4.1->sbnltk) (0.4.6)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow>=2.4.1->sbnltk) (2.2.2)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow>=2.4.1->sbnltk) (59.8.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow>=2.4.1->sbnltk) (3.3.7)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown>=3.12.2->sbnltk) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown>=3.12.2->sbnltk) (1.26.13)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown>=3.12.2->sbnltk) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown>=3.12.2->sbnltk) (2.1.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->gdown>=3.12.2->sbnltk) (2.3.1)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3->pytorch_pretrained_bert>=0.6.2->sbnltk) (1.0.1)\nRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from boto3->pytorch_pretrained_bert>=0.6.2->sbnltk) (0.6.0)\nRequirement already satisfied: botocore<1.30.0,>=1.29.43 in /opt/conda/lib/python3.7/site-packages (from boto3->pytorch_pretrained_bert>=0.6.2->sbnltk) (1.29.43)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers>=4.3.2->sbnltk) (3.8.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk->sentence_transformers->sbnltk) (8.1.3)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown>=3.12.2->sbnltk) (1.7.1)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->sentence_transformers->sbnltk) (9.1.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow>=2.4.1->sbnltk) (4.8)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow>=2.4.1->sbnltk) (0.2.7)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow>=2.4.1->sbnltk) (4.2.4)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow>=2.4.1->sbnltk) (1.3.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=0.11.15->tensorboard<2.7,>=2.6.0->tensorflow>=2.4.1->sbnltk) (2.1.1)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow>=2.4.1->sbnltk) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow>=2.4.1->sbnltk) (3.2.0)\nBuilding wheels for collected packages: sbnltk, sentence_transformers\n  Building wheel for sbnltk (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sbnltk: filename=sbnltk-1.0.7-py3-none-any.whl size=31681 sha256=71e2cad8e8c8048e82b729f14a8dd04ec265fffeb3b67d65d35e29e598cf39f0\n  Stored in directory: /root/.cache/pip/wheels/15/4d/af/47d3e47dd41321f36547e58ecaac6f89c157602415d1775e34\n  Building wheel for sentence_transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=4baa10a1c810aadb430467ea22b79fe1e52d320f55f058a6107b94a1098278b8\n  Stored in directory: /root/.cache/pip/wheels/bf/06/fb/d59c1e5bd1dac7f6cf61ec0036cc3a10ab8fecaa6b2c3d3ee9\nSuccessfully built sbnltk sentence_transformers\nInstalling collected packages: typing-extensions, google_trans_new, numpy, h5py, scikit-learn, gdown, sentence_transformers, pytorch_pretrained_bert, sbnltk\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.1.1\n    Uninstalling typing_extensions-4.1.1:\n      Successfully uninstalled typing_extensions-4.1.1\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.21.6\n    Uninstalling numpy-1.21.6:\n      Successfully uninstalled numpy-1.21.6\n  Attempting uninstall: h5py\n    Found existing installation: h5py 3.7.0\n    Uninstalling h5py-3.7.0:\n      Successfully uninstalled h5py-3.7.0\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.0.2\n    Uninstalling scikit-learn-1.0.2:\n      Successfully uninstalled scikit-learn-1.0.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\nbeatrix-jupyterlab 3.1.7 requires google-cloud-bigquery-storage, which is not installed.\nyellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.2.post1 which is incompatible.\nxarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\ntfx-bsl 1.9.0 requires google-api-python-client<2,>=1.7.11, but you have google-api-python-client 2.52.0 which is incompatible.\ntfx-bsl 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\ntfx-bsl 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\ntensorflow-transform 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\ntensorflow-transform 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\ntensorflow-serving-api 2.9.0 requires tensorflow<3,>=2.9.0, but you have tensorflow 2.6.4 which is incompatible.\ntensorboardx 2.5.1 requires protobuf<=3.20.1,>=3.8.0, but you have protobuf 3.20.3 which is incompatible.\nsklearn-pandas 2.2.0 requires scikit-learn>=0.23.0, but you have scikit-learn 0.22.2.post1 which is incompatible.\nrich 12.6.0 requires typing-extensions<5.0,>=4.0.0; python_version < \"3.9\", but you have typing-extensions 3.10.0.2 which is incompatible.\npytorch-lightning 1.8.6 requires typing-extensions>=4.0.0, but you have typing-extensions 3.10.0.2 which is incompatible.\npytoolconfig 1.2.4 requires typing-extensions>=4.4.0; python_version < \"3.8\", but you have typing-extensions 3.10.0.2 which is incompatible.\npdpbox 0.2.1 requires matplotlib==3.1.1, but you have matplotlib 3.5.3 which is incompatible.\npandas-profiling 3.1.0 requires markupsafe~=2.0.1, but you have markupsafe 2.1.1 which is incompatible.\nortools 9.5.2237 requires protobuf>=4.21.5, but you have protobuf 3.20.3 which is incompatible.\nnnabla 1.32.0 requires numpy>=1.20.0, but you have numpy 1.19.5 which is incompatible.\nnnabla 1.32.0 requires protobuf<=3.19.4; platform_system != \"Windows\", but you have protobuf 3.20.3 which is incompatible.\nmlxtend 0.21.0 requires scikit-learn>=1.0.2, but you have scikit-learn 0.22.2.post1 which is incompatible.\njaxlib 0.3.25 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\njax 0.3.25 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\nimbalanced-learn 0.10.1 requires joblib>=1.1.1, but you have joblib 1.0.1 which is incompatible.\nimbalanced-learn 0.10.1 requires scikit-learn>=1.0.2, but you have scikit-learn 0.22.2.post1 which is incompatible.\nhypertools 0.8.0 requires scikit-learn>=0.24, but you have scikit-learn 0.22.2.post1 which is incompatible.\ngplearn 0.4.2 requires scikit-learn>=1.0.2, but you have scikit-learn 0.22.2.post1 which is incompatible.\nflax 0.6.3 requires typing-extensions>=4.1.1, but you have typing-extensions 3.10.0.2 which is incompatible.\nflake8 5.0.4 requires importlib-metadata<4.3,>=1.1.0; python_version < \"3.8\", but you have importlib-metadata 4.13.0 which is incompatible.\nfeaturetools 1.11.1 requires numpy>=1.21.0, but you have numpy 1.19.5 which is incompatible.\ncmudict 1.0.13 requires importlib-metadata<6.0.0,>=5.1.0, but you have importlib-metadata 4.13.0 which is incompatible.\ncmdstanpy 1.0.8 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\napache-beam 2.40.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\napache-beam 2.40.0 requires pyarrow<8.0.0,>=0.15.1, but you have pyarrow 8.0.0 which is incompatible.\nallennlp 2.10.1 requires h5py>=3.6.0, but you have h5py 3.1.0 which is incompatible.\nallennlp 2.10.1 requires numpy>=1.21.4, but you have numpy 1.19.5 which is incompatible.\nallennlp 2.10.1 requires scikit-learn>=1.0.1, but you have scikit-learn 0.22.2.post1 which is incompatible.\naioitertools 0.11.0 requires typing_extensions>=4.0; python_version < \"3.10\", but you have typing-extensions 3.10.0.2 which is incompatible.\naiobotocore 2.4.2 requires botocore<1.27.60,>=1.27.59, but you have botocore 1.29.43 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed gdown-4.6.0 google_trans_new-1.1.9 h5py-3.1.0 numpy-1.19.5 pytorch_pretrained_bert-0.6.2 sbnltk-1.0.7 scikit-learn-0.22.2.post1 sentence_transformers-2.2.2 typing-extensions-3.10.0.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting simpletransformers\n  Downloading simpletransformers-0.63.9-py3-none-any.whl (250 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.5/250.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (1.7.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (1.19.5)\nCollecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: wandb>=0.10.32 in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (0.12.21)\nRequirement already satisfied: transformers>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (4.20.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (0.22.2.post1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (2.28.1)\nRequirement already satisfied: tokenizers in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (0.12.1)\nCollecting streamlit\n  Downloading streamlit-1.17.0-py2.py3-none-any.whl (9.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (0.1.97)\nRequirement already satisfied: tqdm>=4.47.0 in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (4.64.0)\nRequirement already satisfied: tensorboard in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (2.6.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (2.1.0)\nRequirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (2021.11.10)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (1.3.5)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.6.0->simpletransformers) (0.10.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.6.0->simpletransformers) (6.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers>=4.6.0->simpletransformers) (4.13.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers>=4.6.0->simpletransformers) (3.7.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.6.0->simpletransformers) (22.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (0.4.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (59.8.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (1.3.2)\nRequirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (1.0.11)\nRequirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (8.1.3)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (5.9.1)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (1.12.1)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (0.1.2)\nRequirement already satisfied: protobuf<4.0dev,>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (3.20.3)\nRequirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (2.3)\nRequirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (1.15.0)\nRequirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (3.1.27)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->simpletransformers) (2022.12.7)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->simpletransformers) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->simpletransformers) (1.26.13)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->simpletransformers) (3.3)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets->simpletransformers) (8.0.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets->simpletransformers) (3.2.0)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets->simpletransformers) (0.18.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets->simpletransformers) (3.8.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets->simpletransformers) (0.70.14)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets->simpletransformers) (0.3.6)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets->simpletransformers) (2022.11.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->simpletransformers) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->simpletransformers) (2022.1)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->simpletransformers) (1.0.1)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from streamlit->simpletransformers) (9.1.1)\nRequirement already satisfied: blinker>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from streamlit->simpletransformers) (1.4)\nRequirement already satisfied: toml in /opt/conda/lib/python3.7/site-packages (from streamlit->simpletransformers) (0.10.2)\nRequirement already satisfied: typing-extensions>=3.10.0.0 in /opt/conda/lib/python3.7/site-packages (from streamlit->simpletransformers) (3.10.0.2)\nRequirement already satisfied: cachetools>=4.0 in /opt/conda/lib/python3.7/site-packages (from streamlit->simpletransformers) (4.2.4)\nRequirement already satisfied: pympler>=0.9 in /opt/conda/lib/python3.7/site-packages (from streamlit->simpletransformers) (1.0.1)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.7/site-packages (from streamlit->simpletransformers) (12.6.0)\nRequirement already satisfied: altair>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from streamlit->simpletransformers) (4.2.0)\nCollecting pydeck>=0.1.dev5\n  Downloading pydeck-0.8.0-py2.py3-none-any.whl (4.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tzlocal>=1.1 in /opt/conda/lib/python3.7/site-packages (from streamlit->simpletransformers) (4.2)\nCollecting validators>=0.2\n  Downloading validators-0.20.0.tar.gz (30 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tornado>=5.0 in /opt/conda/lib/python3.7/site-packages (from streamlit->simpletransformers) (6.1)\nCollecting watchdog\n  Downloading watchdog-2.2.1-py3-none-manylinux2014_x86_64.whl (78 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.0/79.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: semver in /opt/conda/lib/python3.7/site-packages (from streamlit->simpletransformers) (2.13.0)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard->simpletransformers) (0.37.1)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->simpletransformers) (1.8.1)\nRequirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->simpletransformers) (1.47.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard->simpletransformers) (2.2.2)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard->simpletransformers) (0.4.6)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard->simpletransformers) (3.3.7)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->simpletransformers) (0.6.1)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard->simpletransformers) (0.15.0)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->simpletransformers) (1.35.0)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.7/site-packages (from altair>=3.2.0->streamlit->simpletransformers) (4.6.1)\nRequirement already satisfied: entrypoints in /opt/conda/lib/python3.7/site-packages (from altair>=3.2.0->streamlit->simpletransformers) (0.4)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.7/site-packages (from altair>=3.2.0->streamlit->simpletransformers) (0.11.2)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from altair>=3.2.0->streamlit->simpletransformers) (3.1.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->simpletransformers) (21.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->simpletransformers) (1.3.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->simpletransformers) (1.7.2)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->simpletransformers) (4.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->simpletransformers) (1.2.0)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->simpletransformers) (0.13.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->simpletransformers) (6.0.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb>=0.10.32->simpletransformers) (4.0.9)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->simpletransformers) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->simpletransformers) (4.8)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->simpletransformers) (1.3.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers>=4.6.0->simpletransformers) (3.8.0)\nRequirement already satisfied: commonmark<0.10.0,>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from rich>=10.11.0->streamlit->simpletransformers) (0.9.1)\nCollecting typing-extensions>=3.10.0.0\n  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\nRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from rich>=10.11.0->streamlit->simpletransformers) (2.12.0)\nRequirement already satisfied: pytz-deprecation-shim in /opt/conda/lib/python3.7/site-packages (from tzlocal>=1.1->streamlit->simpletransformers) (0.1.0.post0)\nRequirement already satisfied: backports.zoneinfo in /opt/conda/lib/python3.7/site-packages (from tzlocal>=1.1->streamlit->simpletransformers) (0.2.1)\nRequirement already satisfied: decorator>=3.4.0 in /opt/conda/lib/python3.7/site-packages (from validators>=0.2->streamlit->simpletransformers) (5.1.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=0.11.15->tensorboard->simpletransformers) (2.1.1)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb>=0.10.32->simpletransformers) (3.0.5)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit->simpletransformers) (0.18.1)\nRequirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit->simpletransformers) (5.10.2)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->simpletransformers) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->simpletransformers) (3.2.0)\nRequirement already satisfied: tzdata in /opt/conda/lib/python3.7/site-packages (from pytz-deprecation-shim->tzlocal>=1.1->streamlit->simpletransformers) (2022.7)\nBuilding wheels for collected packages: seqeval, validators\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=c0b6292776869c01fc131ec0c81513ced44748f0d4b6965081acaf3f2ef7cc2e\n  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n  Building wheel for validators (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19582 sha256=cc52564efd6c3eac75e618d1c6fd224ac14ddd5b38e9b9977c618f12948629b8\n  Stored in directory: /root/.cache/pip/wheels/5f/55/ab/36a76989f7f88d9ca7b1f68da6d94252bb6a8d6ad4f18e04e9\nSuccessfully built seqeval validators\nInstalling collected packages: watchdog, validators, typing-extensions, pydeck, seqeval, streamlit, simpletransformers\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing-extensions 3.10.0.2\n    Uninstalling typing-extensions-3.10.0.2:\n      Successfully uninstalled typing-extensions-3.10.0.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\nxarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\nthinc 8.0.17 requires typing-extensions<4.2.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.4.0 which is incompatible.\ntensorflow 2.6.4 requires typing-extensions<3.11,>=3.7, but you have typing-extensions 4.4.0 which is incompatible.\ntensorflow-transform 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\ntensorflow-transform 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\ntensorflow-serving-api 2.9.0 requires tensorflow<3,>=2.9.0, but you have tensorflow 2.6.4 which is incompatible.\nspacy 3.3.2 requires typing-extensions<4.2.0,>=3.7.4; python_version < \"3.8\", but you have typing-extensions 4.4.0 which is incompatible.\npandas-profiling 3.1.0 requires markupsafe~=2.0.1, but you have markupsafe 2.1.1 which is incompatible.\njax 0.3.25 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\nflake8 5.0.4 requires importlib-metadata<4.3,>=1.1.0; python_version < \"3.8\", but you have importlib-metadata 4.13.0 which is incompatible.\nconfection 0.0.3 requires typing-extensions<4.2.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.4.0 which is incompatible.\ncmudict 1.0.13 requires importlib-metadata<6.0.0,>=5.1.0, but you have importlib-metadata 4.13.0 which is incompatible.\napache-beam 2.40.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\napache-beam 2.40.0 requires pyarrow<8.0.0,>=0.15.1, but you have pyarrow 8.0.0 which is incompatible.\nallennlp 2.10.1 requires h5py>=3.6.0, but you have h5py 3.1.0 which is incompatible.\nallennlp 2.10.1 requires numpy>=1.21.4, but you have numpy 1.19.5 which is incompatible.\nallennlp 2.10.1 requires scikit-learn>=1.0.1, but you have scikit-learn 0.22.2.post1 which is incompatible.\naiobotocore 2.4.2 requires botocore<1.27.60,>=1.27.59, but you have botocore 1.29.43 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pydeck-0.8.0 seqeval-1.2.2 simpletransformers-0.63.9 streamlit-1.17.0 typing-extensions-4.4.0 validators-0.20.0 watchdog-2.2.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip uninstall scikit-learn -y","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:47:46.095564Z","iopub.execute_input":"2023-01-21T08:47:46.096097Z","iopub.status.idle":"2023-01-21T08:47:48.718288Z","shell.execute_reply.started":"2023-01-21T08:47:46.096047Z","shell.execute_reply":"2023-01-21T08:47:48.716654Z"},"trusted":true},"execution_count":115,"outputs":[{"name":"stdout","text":"Found existing installation: scikit-learn 0.22.2.post1\nUninstalling scikit-learn-0.22.2.post1:\n  Successfully uninstalled scikit-learn-0.22.2.post1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install scikit-learn","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:47:48.720454Z","iopub.execute_input":"2023-01-21T08:47:48.721004Z","iopub.status.idle":"2023-01-21T08:48:04.661134Z","shell.execute_reply.started":"2023-01-21T08:47:48.720952Z","shell.execute_reply":"2023-01-21T08:48:04.659364Z"},"trusted":true},"execution_count":116,"outputs":[{"name":"stdout","text":"Collecting scikit-learn\n  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.8/24.8 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (1.7.3)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (1.0.1)\nRequirement already satisfied: numpy>=1.14.6 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (1.19.5)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (3.1.0)\nInstalling collected packages: scikit-learn\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nsbnltk 1.0.7 requires scikit-learn==0.22.2.post1, but you have scikit-learn 1.0.2 which is incompatible.\nimbalanced-learn 0.10.1 requires joblib>=1.1.1, but you have joblib 1.0.1 which is incompatible.\nfeaturetools 1.11.1 requires numpy>=1.21.0, but you have numpy 1.19.5 which is incompatible.\nallennlp 2.10.1 requires h5py>=3.6.0, but you have h5py 3.1.0 which is incompatible.\nallennlp 2.10.1 requires numpy>=1.21.4, but you have numpy 1.19.5 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed scikit-learn-1.0.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.mixture import GaussianMixture","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:48:04.664134Z","iopub.execute_input":"2023-01-21T08:48:04.664504Z","iopub.status.idle":"2023-01-21T08:48:04.718304Z","shell.execute_reply.started":"2023-01-21T08:48:04.664471Z","shell.execute_reply":"2023-01-21T08:48:04.717066Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport string \n\npunctuations = list(string.punctuation) + ['।']\nprint(punctuations)","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:20:46.966767Z","iopub.execute_input":"2023-01-21T09:20:46.967260Z","iopub.status.idle":"2023-01-21T09:20:46.974304Z","shell.execute_reply.started":"2023-01-21T09:20:46.967225Z","shell.execute_reply":"2023-01-21T09:20:46.973077Z"},"trusted":true},"execution_count":141,"outputs":[{"name":"stdout","text":"['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', '।']\n","output_type":"stream"}]},{"cell_type":"code","source":"def load_data(filename):\n    with open(filename, 'r',encoding='utf-8') as f:\n        data = [line.strip().split(' _ _ ') for line in f.readlines()]\n        # return data\n        # empty lines are used to separate sentences\n        # separate them into sentences\n        sentences = []\n        cur = []\n        for line in data:\n            if line == ['']:\n                cur = [tuple(line) for line in cur]\n                sentences.append(cur)\n                cur = []\n            else:\n#                 for p in punctuations:\n#                     line[0] = line[0].replace(p, '')\n                if len(line[0]) == 0:\n                    line[0] = ' '\n                cur.append(line)\n        # # convert each list to a tuple\n        sentences.append(cur)\n        return sentences","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:56:01.757819Z","iopub.execute_input":"2023-01-21T09:56:01.758222Z","iopub.status.idle":"2023-01-21T09:56:01.767504Z","shell.execute_reply.started":"2023-01-21T09:56:01.758192Z","shell.execute_reply":"2023-01-21T09:56:01.765985Z"},"trusted":true},"execution_count":193,"outputs":[]},{"cell_type":"code","source":"def load_words(filename):\n    with open(filename, 'r',encoding='utf-8') as f:\n        data = [line.strip().split(' _ _ ') for line in f.readlines()]\n        words = []\n        for line in data:\n            if line == ['']:\n                continue\n            else:\n                words.append(line[0])\n        # # convert each list to a tuple\n        return list(set(words))","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:56:04.077336Z","iopub.execute_input":"2023-01-21T09:56:04.077783Z","iopub.status.idle":"2023-01-21T09:56:04.085315Z","shell.execute_reply.started":"2023-01-21T09:56:04.077745Z","shell.execute_reply":"2023-01-21T09:56:04.084239Z"},"trusted":true},"execution_count":194,"outputs":[]},{"cell_type":"code","source":"train_words_set = load_words('/kaggle/input/bdosn-nlp-hackathon-2023/train.txt')\ndev_words_set = load_words('/kaggle/input/bdosn-nlp-hackathon-2023/dev.txt')","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:56:05.501262Z","iopub.execute_input":"2023-01-21T09:56:05.501727Z","iopub.status.idle":"2023-01-21T09:56:06.681835Z","shell.execute_reply.started":"2023-01-21T09:56:05.501689Z","shell.execute_reply":"2023-01-21T09:56:06.680525Z"},"trusted":true},"execution_count":195,"outputs":[]},{"cell_type":"code","source":"len(dev_words_set), dev_words_set[:10]","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:56:06.683929Z","iopub.execute_input":"2023-01-21T09:56:06.684298Z","iopub.status.idle":"2023-01-21T09:56:06.691944Z","shell.execute_reply.started":"2023-01-21T09:56:06.684265Z","shell.execute_reply":"2023-01-21T09:56:06.690642Z"},"trusted":true},"execution_count":196,"outputs":[{"execution_count":196,"output_type":"execute_result","data":{"text/plain":"(4713,\n ['হারমোনিকা',\n  'চেয়ারটি',\n  'উৎপাদিত',\n  'সম্পর্কে।',\n  'ভোকাল',\n  'বস্তুবাদে',\n  'পরেন।',\n  'রাজকীয়ভাবে',\n  'সুখী',\n  'রিজেনরন'])"},"metadata":{}}]},{"cell_type":"code","source":"import os\nos.listdir('/kaggle/input/bdosn-nlp-hackathon-2023/')","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:56:07.662700Z","iopub.execute_input":"2023-01-21T09:56:07.663545Z","iopub.status.idle":"2023-01-21T09:56:07.673925Z","shell.execute_reply.started":"2023-01-21T09:56:07.663505Z","shell.execute_reply":"2023-01-21T09:56:07.672973Z"},"trusted":true},"execution_count":197,"outputs":[{"execution_count":197,"output_type":"execute_result","data":{"text/plain":"['location.txt',\n 'album_names_bn.txt',\n 'location_names_bn.txt',\n 'test.txt',\n 'names_bn.txt',\n 'gazetters',\n 'train.txt',\n 'dev.txt',\n 'test_labels_dummy.txt',\n 'location_small.txt',\n 'movies_bn.txt']"},"metadata":{}}]},{"cell_type":"code","source":"from sbnltk.word_embedding import gensim_word2vec_embedding\nw2v=gensim_word2vec_embedding()","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:56:08.042775Z","iopub.execute_input":"2023-01-21T09:56:08.043504Z","iopub.status.idle":"2023-01-21T09:56:50.510142Z","shell.execute_reply.started":"2023-01-21T09:56:08.043460Z","shell.execute_reply":"2023-01-21T09:56:50.508784Z"},"trusted":true},"execution_count":198,"outputs":[]},{"cell_type":"code","source":"def get_w2v(words):\n    ret = []\n    for word in words:\n        ret.append(w2v.get_vector(word))\n    return np.asarray(ret)\n\ndef get_cluster_id(words):\n    words_w2v = get_w2v(words)\n    kmeans = KMeans(n_clusters=500, random_state=0).fit(words_w2v)\n    return kmeans.labels_, kmeans","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:56:50.512027Z","iopub.execute_input":"2023-01-21T09:56:50.512397Z","iopub.status.idle":"2023-01-21T09:56:50.519258Z","shell.execute_reply.started":"2023-01-21T09:56:50.512365Z","shell.execute_reply":"2023-01-21T09:56:50.518075Z"},"trusted":true},"execution_count":199,"outputs":[]},{"cell_type":"code","source":"train_words_w2v = get_w2v(train_words_set)","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:56:50.520786Z","iopub.execute_input":"2023-01-21T09:56:50.521290Z","iopub.status.idle":"2023-01-21T09:56:50.626666Z","shell.execute_reply.started":"2023-01-21T09:56:50.521242Z","shell.execute_reply":"2023-01-21T09:56:50.625380Z"},"trusted":true},"execution_count":200,"outputs":[]},{"cell_type":"code","source":"dev_words_w2v = get_w2v(dev_words_set)","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:56:50.629996Z","iopub.execute_input":"2023-01-21T09:56:50.630994Z","iopub.status.idle":"2023-01-21T09:56:50.650864Z","shell.execute_reply.started":"2023-01-21T09:56:50.630940Z","shell.execute_reply":"2023-01-21T09:56:50.649501Z"},"trusted":true},"execution_count":201,"outputs":[]},{"cell_type":"code","source":"# gmm = GaussianMixture(n_components=500, random_state=0).fit(train_words_w2v)","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:56:50.653065Z","iopub.execute_input":"2023-01-21T09:56:50.653614Z","iopub.status.idle":"2023-01-21T09:56:50.659173Z","shell.execute_reply.started":"2023-01-21T09:56:50.653544Z","shell.execute_reply":"2023-01-21T09:56:50.657784Z"},"trusted":true},"execution_count":202,"outputs":[]},{"cell_type":"code","source":"kmeans = KMeans(n_clusters=500, random_state=0).fit(train_words_w2v)","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:56:50.661405Z","iopub.execute_input":"2023-01-21T09:56:50.662055Z","iopub.status.idle":"2023-01-21T09:59:25.907286Z","shell.execute_reply.started":"2023-01-21T09:56:50.662019Z","shell.execute_reply":"2023-01-21T09:59:25.906121Z"},"trusted":true},"execution_count":203,"outputs":[]},{"cell_type":"code","source":"kmeans.labels_","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:59:25.909064Z","iopub.execute_input":"2023-01-21T09:59:25.909462Z","iopub.status.idle":"2023-01-21T09:59:25.917422Z","shell.execute_reply.started":"2023-01-21T09:59:25.909425Z","shell.execute_reply":"2023-01-21T09:59:25.916140Z"},"trusted":true},"execution_count":204,"outputs":[{"execution_count":204,"output_type":"execute_result","data":{"text/plain":"array([489, 489,   4, ...,   7,   4, 485], dtype=int32)"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"kmeans.predict(train_words_w2v[0:2])","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:59:25.920127Z","iopub.execute_input":"2023-01-21T09:59:25.921011Z","iopub.status.idle":"2023-01-21T09:59:25.932126Z","shell.execute_reply.started":"2023-01-21T09:59:25.920962Z","shell.execute_reply":"2023-01-21T09:59:25.931108Z"},"trusted":true},"execution_count":205,"outputs":[{"execution_count":205,"output_type":"execute_result","data":{"text/plain":"array([489, 489], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"# gmm.predict(train_words_w2v[0:2])","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:59:25.933850Z","iopub.execute_input":"2023-01-21T09:59:25.934632Z","iopub.status.idle":"2023-01-21T09:59:25.947803Z","shell.execute_reply.started":"2023-01-21T09:59:25.934576Z","shell.execute_reply":"2023-01-21T09:59:25.946549Z"},"trusted":true},"execution_count":206,"outputs":[]},{"cell_type":"code","source":"train = load_data('/kaggle/input/bdosn-nlp-hackathon-2023/train.txt')","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:59:25.952046Z","iopub.execute_input":"2023-01-21T09:59:25.952458Z","iopub.status.idle":"2023-01-21T09:59:26.706218Z","shell.execute_reply.started":"2023-01-21T09:59:25.952424Z","shell.execute_reply":"2023-01-21T09:59:26.704862Z"},"trusted":true},"execution_count":207,"outputs":[]},{"cell_type":"code","source":"dev = load_data('/kaggle/input/bdosn-nlp-hackathon-2023/dev.txt')","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:59:26.709744Z","iopub.execute_input":"2023-01-21T09:59:26.711084Z","iopub.status.idle":"2023-01-21T09:59:26.738144Z","shell.execute_reply.started":"2023-01-21T09:59:26.711039Z","shell.execute_reply":"2023-01-21T09:59:26.737185Z"},"trusted":true},"execution_count":208,"outputs":[]},{"cell_type":"code","source":"dev[6]","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:59:26.739409Z","iopub.execute_input":"2023-01-21T09:59:26.740417Z","iopub.status.idle":"2023-01-21T09:59:26.748275Z","shell.execute_reply.started":"2023-01-21T09:59:26.740378Z","shell.execute_reply":"2023-01-21T09:59:26.746981Z"},"trusted":true},"execution_count":209,"outputs":[{"execution_count":209,"output_type":"execute_result","data":{"text/plain":"[('আরিয়ানা', 'B-PER'),\n ('গ্রান্দে', 'I-PER'),\n ('-', 'O'),\n ('লিড', 'O'),\n ('ভোকাল,', 'O'),\n ('ব্যাকগ্রাউন্ড', 'O'),\n ('ভোকাল,', 'O'),\n ('গান', 'O'),\n ('রচনা,', 'O'),\n ('ভোকাল', 'O'),\n ('প্রোডাকশন,', 'O'),\n ('ভোকাল', 'O'),\n ('অ্যারেঞ্জমেন্ট,', 'O'),\n ('অডিও', 'O'),\n ('ইঞ্জিনিয়ারিং', 'O')]"},"metadata":{}}]},{"cell_type":"code","source":"train[0]","metadata":{"execution":{"iopub.status.busy":"2023-01-21T10:00:02.031359Z","iopub.execute_input":"2023-01-21T10:00:02.031904Z","iopub.status.idle":"2023-01-21T10:00:02.041058Z","shell.execute_reply.started":"2023-01-21T10:00:02.031858Z","shell.execute_reply":"2023-01-21T10:00:02.039907Z"},"trusted":true},"execution_count":210,"outputs":[{"execution_count":210,"output_type":"execute_result","data":{"text/plain":"[('তার', 'O'),\n ('মৃত্যুর', 'O'),\n ('দশ', 'O'),\n ('দিন', 'O'),\n ('পর,', 'O'),\n ('১১৫', 'O'),\n ('কৃষ্ণাঙ্গ', 'O'),\n ('উচ্চ', 'O'),\n ('বিদ্যালয়ের', 'O'),\n ('শিক্ষার্থীরা', 'O'),\n ('তার', 'O'),\n ('হত্যার', 'O'),\n ('প্রতিবাদে', 'O'),\n ('ম্যাককম্ব', 'B-LOC'),\n ('এর', 'O'),\n ('মাধ্যমে', 'O'),\n ('মিছিল', 'O'),\n ('করেছে।', 'O')]"},"metadata":{}}]},{"cell_type":"code","source":"!pip install bnlp_toolkit","metadata":{"execution":{"iopub.status.busy":"2023-01-21T10:00:02.860278Z","iopub.execute_input":"2023-01-21T10:00:02.860920Z","iopub.status.idle":"2023-01-21T10:00:14.596659Z","shell.execute_reply.started":"2023-01-21T10:00:02.860863Z","shell.execute_reply":"2023-01-21T10:00:14.594870Z"},"trusted":true},"execution_count":211,"outputs":[{"name":"stdout","text":"Requirement already satisfied: bnlp_toolkit in /opt/conda/lib/python3.7/site-packages (3.2.0)\nRequirement already satisfied: wasabi in /opt/conda/lib/python3.7/site-packages (from bnlp_toolkit) (0.10.1)\nRequirement already satisfied: sklearn-crfsuite in /opt/conda/lib/python3.7/site-packages (from bnlp_toolkit) (0.3.6)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from bnlp_toolkit) (1.19.5)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from bnlp_toolkit) (4.64.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from bnlp_toolkit) (3.8.1)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from bnlp_toolkit) (1.7.3)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from bnlp_toolkit) (0.1.97)\nRequirement already satisfied: gensim==4.0.1 in /opt/conda/lib/python3.7/site-packages (from bnlp_toolkit) (4.0.1)\nRequirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim==4.0.1->bnlp_toolkit) (6.3.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk->bnlp_toolkit) (1.0.1)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk->bnlp_toolkit) (8.1.3)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk->bnlp_toolkit) (2021.11.10)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sklearn-crfsuite->bnlp_toolkit) (1.15.0)\nRequirement already satisfied: python-crfsuite>=0.8.3 in /opt/conda/lib/python3.7/site-packages (from sklearn-crfsuite->bnlp_toolkit) (0.9.8)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from sklearn-crfsuite->bnlp_toolkit) (0.9.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->nltk->bnlp_toolkit) (4.13.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk->bnlp_toolkit) (3.8.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk->bnlp_toolkit) (4.4.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/sagorbrur/bnlp","metadata":{"execution":{"iopub.status.busy":"2023-01-21T10:00:14.599296Z","iopub.execute_input":"2023-01-21T10:00:14.599780Z","iopub.status.idle":"2023-01-21T10:00:15.811625Z","shell.execute_reply.started":"2023-01-21T10:00:14.599685Z","shell.execute_reply":"2023-01-21T10:00:15.810055Z"},"trusted":true},"execution_count":212,"outputs":[{"name":"stdout","text":"fatal: destination path 'bnlp' already exists and is not an empty directory.\n","output_type":"stream"}]},{"cell_type":"code","source":"from bnlp import POS\nbn_pos = POS()\nmodel_path = \"/kaggle/working/bnlp/model/bn_pos.pkl\"\ntext = \"আমি ভাত খাই।\" # or you can pass ['আমি', 'ভাত', 'খাই', '।']\nres = bn_pos.tag(model_path, text)\nprint(res)\n# [('আমি', 'PPR'), ('ভাত', 'NC'), ('খাই', 'VM'), ('।', 'PU')]","metadata":{"execution":{"iopub.status.busy":"2023-01-21T10:00:15.813675Z","iopub.execute_input":"2023-01-21T10:00:15.814356Z","iopub.status.idle":"2023-01-21T10:00:15.852786Z","shell.execute_reply.started":"2023-01-21T10:00:15.814315Z","shell.execute_reply":"2023-01-21T10:00:15.851426Z"},"trusted":true},"execution_count":213,"outputs":[{"name":"stdout","text":"[('আমি', 'PPR'), ('ভাত', 'NC'), ('খাই', 'VM'), ('।', 'PU')]\n","output_type":"stream"}]},{"cell_type":"code","source":"def add_pos(sentence):\n    # first one of the tuple is the word and the second one is the ner  \n    words = []\n    for word in sentence:\n        words.append(word[0])\n    pos = bn_pos.tag(model_path, words)\n    ## add ner back to the tuple\n    ret = []\n    for i in range(len(pos)):\n        word = sentence[i][0]\n        ner = sentence[i][1]\n        ret.append((word, pos[i][1], ner))\n    return ret\n\ndef add_pos_to_all(sents):\n    ret = []\n    for i in range(len(sents)):\n        if i % 100 == 0:\n            print(i)\n        ret.append(add_pos(sents[i]))\n    return ret","metadata":{"execution":{"iopub.status.busy":"2023-01-21T10:00:15.855502Z","iopub.execute_input":"2023-01-21T10:00:15.855916Z","iopub.status.idle":"2023-01-21T10:00:15.866109Z","shell.execute_reply.started":"2023-01-21T10:00:15.855880Z","shell.execute_reply":"2023-01-21T10:00:15.864455Z"},"trusted":true},"execution_count":214,"outputs":[]},{"cell_type":"code","source":"add_pos(train[0])","metadata":{"execution":{"iopub.status.busy":"2023-01-21T10:00:15.867807Z","iopub.execute_input":"2023-01-21T10:00:15.868213Z","iopub.status.idle":"2023-01-21T10:00:15.914859Z","shell.execute_reply.started":"2023-01-21T10:00:15.868177Z","shell.execute_reply":"2023-01-21T10:00:15.913508Z"},"trusted":true},"execution_count":215,"outputs":[{"execution_count":215,"output_type":"execute_result","data":{"text/plain":"[('তার', 'PPR', 'O'),\n ('মৃত্যুর', 'NC', 'O'),\n ('দশ', 'JQ', 'O'),\n ('দিন', 'NC', 'O'),\n ('পর,', 'NC', 'O'),\n ('১১৫', 'RDF', 'O'),\n ('কৃষ্ণাঙ্গ', 'NC', 'O'),\n ('উচ্চ', 'JJ', 'O'),\n ('বিদ্যালয়ের', 'NC', 'O'),\n ('শিক্ষার্থীরা', 'NC', 'O'),\n ('তার', 'PPR', 'O'),\n ('হত্যার', 'NC', 'O'),\n ('প্রতিবাদে', 'NC', 'O'),\n ('ম্যাককম্ব', 'NC', 'B-LOC'),\n ('এর', 'PPR', 'O'),\n ('মাধ্যমে', 'PP', 'O'),\n ('মিছিল', 'NC', 'O'),\n ('করেছে।', 'VM', 'O')]"},"metadata":{}}]},{"cell_type":"code","source":"train_sents =  add_pos_to_all(train)","metadata":{"execution":{"iopub.status.busy":"2023-01-21T10:00:15.916326Z","iopub.execute_input":"2023-01-21T10:00:15.916731Z","iopub.status.idle":"2023-01-21T10:06:55.430336Z","shell.execute_reply.started":"2023-01-21T10:00:15.916688Z","shell.execute_reply":"2023-01-21T10:06:55.428986Z"},"trusted":true},"execution_count":216,"outputs":[{"name":"stdout","text":"0\n100\n200\n300\n400\n500\n600\n700\n800\n900\n1000\n1100\n1200\n1300\n1400\n1500\n1600\n1700\n1800\n1900\n2000\n2100\n2200\n2300\n2400\n2500\n2600\n2700\n2800\n2900\n3000\n3100\n3200\n3300\n3400\n3500\n3600\n3700\n3800\n3900\n4000\n4100\n4200\n4300\n4400\n4500\n4600\n4700\n4800\n4900\n5000\n5100\n5200\n5300\n5400\n5500\n5600\n5700\n5800\n5900\n6000\n6100\n6200\n6300\n6400\n6500\n6600\n6700\n6800\n6900\n7000\n7100\n7200\n7300\n7400\n7500\n7600\n7700\n7800\n7900\n8000\n8100\n8200\n8300\n8400\n8500\n8600\n8700\n8800\n8900\n9000\n9100\n9200\n9300\n9400\n9500\n9600\n9700\n9800\n9900\n10000\n10100\n10200\n10300\n10400\n10500\n10600\n10700\n10800\n10900\n11000\n11100\n11200\n11300\n11400\n11500\n11600\n11700\n11800\n11900\n12000\n12100\n12200\n12300\n12400\n12500\n12600\n12700\n12800\n12900\n13000\n13100\n13200\n13300\n13400\n13500\n13600\n13700\n13800\n13900\n14000\n14100\n14200\n14300\n14400\n14500\n14600\n14700\n14800\n14900\n15000\n15100\n15200\n","output_type":"stream"}]},{"cell_type":"code","source":"dev_sents = add_pos_to_all(dev)","metadata":{"execution":{"iopub.status.busy":"2023-01-21T10:06:55.432064Z","iopub.execute_input":"2023-01-21T10:06:55.433825Z","iopub.status.idle":"2023-01-21T10:07:20.072752Z","shell.execute_reply.started":"2023-01-21T10:06:55.433773Z","shell.execute_reply":"2023-01-21T10:07:20.071777Z"},"trusted":true},"execution_count":217,"outputs":[{"name":"stdout","text":"0\n100\n200\n300\n400\n500\n600\n700\n","output_type":"stream"}]},{"cell_type":"code","source":"train_sents[0]","metadata":{"execution":{"iopub.status.busy":"2023-01-21T10:07:20.076838Z","iopub.execute_input":"2023-01-21T10:07:20.077203Z","iopub.status.idle":"2023-01-21T10:07:20.086955Z","shell.execute_reply.started":"2023-01-21T10:07:20.077170Z","shell.execute_reply":"2023-01-21T10:07:20.085557Z"},"trusted":true},"execution_count":218,"outputs":[{"execution_count":218,"output_type":"execute_result","data":{"text/plain":"[('তার', 'PPR', 'O'),\n ('মৃত্যুর', 'NC', 'O'),\n ('দশ', 'JQ', 'O'),\n ('দিন', 'NC', 'O'),\n ('পর,', 'NC', 'O'),\n ('১১৫', 'RDF', 'O'),\n ('কৃষ্ণাঙ্গ', 'NC', 'O'),\n ('উচ্চ', 'JJ', 'O'),\n ('বিদ্যালয়ের', 'NC', 'O'),\n ('শিক্ষার্থীরা', 'NC', 'O'),\n ('তার', 'PPR', 'O'),\n ('হত্যার', 'NC', 'O'),\n ('প্রতিবাদে', 'NC', 'O'),\n ('ম্যাককম্ব', 'NC', 'B-LOC'),\n ('এর', 'PPR', 'O'),\n ('মাধ্যমে', 'PP', 'O'),\n ('মিছিল', 'NC', 'O'),\n ('করেছে।', 'VM', 'O')]"},"metadata":{}}]},{"cell_type":"code","source":"dev_sents[0]","metadata":{"execution":{"iopub.status.busy":"2023-01-21T10:07:20.088786Z","iopub.execute_input":"2023-01-21T10:07:20.089238Z","iopub.status.idle":"2023-01-21T10:07:20.603169Z","shell.execute_reply.started":"2023-01-21T10:07:20.089194Z","shell.execute_reply":"2023-01-21T10:07:20.601932Z"},"trusted":true},"execution_count":219,"outputs":[{"execution_count":219,"output_type":"execute_result","data":{"text/plain":"[('তিনি', 'PPR', 'O'),\n ('যুবক', 'NC', 'O'),\n ('হিসেবে', 'PP', 'O'),\n ('শেফিল্ড', 'NP', 'B-GRP'),\n ('বুধবার', 'NP', 'I-GRP'),\n ('এফ.সি.', 'NP', 'I-GRP'),\n ('যোগদান', 'NC', 'O'),\n ('করেন', 'VM', 'O'),\n ('এবং', 'CCD', 'O'),\n ('১৯৫১', 'RDF', 'O'),\n ('সালে', 'NC', 'O'),\n ('তাদের', 'PPR', 'O'),\n ('পেশাগত', 'JJ', 'O'),\n ('দিক', 'NC', 'O'),\n ('দিয়ে', 'NC', 'O'),\n ('আত্মপ্রকাশ', 'NC', 'O'),\n ('করেন।', 'VM', 'O')]"},"metadata":{}}]},{"cell_type":"code","source":"!pip3 install tensorflow-hub","metadata":{"execution":{"iopub.status.busy":"2023-01-21T10:07:20.608326Z","iopub.execute_input":"2023-01-21T10:07:20.608740Z","iopub.status.idle":"2023-01-21T10:07:31.934292Z","shell.execute_reply.started":"2023-01-21T10:07:20.608706Z","shell.execute_reply":"2023-01-21T10:07:31.932557Z"},"trusted":true},"execution_count":220,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow-hub in /opt/conda/lib/python3.7/site-packages (0.12.0)\nRequirement already satisfied: protobuf>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-hub) (3.20.3)\nRequirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-hub) (1.19.5)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"def get_all_words(sents):\n    words = []\n    for i in range(len(sents)):\n        for w in sents[i]:\n            words += [w[0]]\n    return words","metadata":{"execution":{"iopub.status.busy":"2023-01-21T10:07:31.937381Z","iopub.execute_input":"2023-01-21T10:07:31.937871Z","iopub.status.idle":"2023-01-21T10:07:31.945239Z","shell.execute_reply.started":"2023-01-21T10:07:31.937826Z","shell.execute_reply":"2023-01-21T10:07:31.943215Z"},"trusted":true},"execution_count":221,"outputs":[]},{"cell_type":"code","source":"all_train_words = get_all_words(train_sents)\nlen(all_train_words)","metadata":{"execution":{"iopub.status.busy":"2023-01-21T10:07:31.947562Z","iopub.execute_input":"2023-01-21T10:07:31.948149Z","iopub.status.idle":"2023-01-21T10:07:32.151494Z","shell.execute_reply.started":"2023-01-21T10:07:31.948098Z","shell.execute_reply":"2023-01-21T10:07:32.150305Z"},"trusted":true},"execution_count":222,"outputs":[{"execution_count":222,"output_type":"execute_result","data":{"text/plain":"191897"},"metadata":{}}]},{"cell_type":"code","source":"word_freq = {}\nfor w in all_train_words:\n    if w in word_freq:\n        word_freq[w] += 1\n    else:\n        word_freq[w] = 1","metadata":{"execution":{"iopub.status.busy":"2023-01-21T10:07:32.153332Z","iopub.execute_input":"2023-01-21T10:07:32.154102Z","iopub.status.idle":"2023-01-21T10:07:32.248165Z","shell.execute_reply.started":"2023-01-21T10:07:32.154056Z","shell.execute_reply":"2023-01-21T10:07:32.246871Z"},"trusted":true},"execution_count":223,"outputs":[]},{"cell_type":"code","source":"# Load the Gazetters\n\nalbum_names_bn = {}\nmovies_bn = {}\nnames_bn = {}\nlocations_bn = {}\n\nwith open('/kaggle/input/bdosn-nlp-hackathon-2023/album_names_bn.txt') as file:\n    lines = [x.strip() for x in file.readlines()]\n    for l in lines:\n        album_names_bn[l] = 1\n        words = l.split()\n        for size in range(2, 4, 1):\n            for i in range(len(words)):\n                if (i + size) >= len(words):\n                    break\n                album_names_bn[\" \".join(words[i: i+size])] = 1\n\nwith open('/kaggle/input/bdosn-nlp-hackathon-2023/movies_bn.txt') as file:\n    lines = [x.strip() for x in file.readlines()]\n    for l in lines:\n        movies_bn[l] = 1\n        words = l.split()\n        for size in range(2, 4, 1):\n            for i in range(len(words)):\n                if (i + size) > len(words):\n                    break\n                movies_bn[\" \".join(words[i: i+size])] = 1\n\nwith open('/kaggle/input/bdosn-nlp-hackathon-2023/location_names_bn.txt') as file:\n    lines = [x.strip() for x in file.readlines()]\n    for l in lines:\n        locations_bn[l] = 1\n        words = l.split()\n        for size in range(2, 4, 1):\n            for i in range(len(words)):\n                if (i + size) >= len(words):\n                    break\n                locations_bn[\" \".join(words[i: i+size])] = 1\n\n\nwith open('/kaggle/input/bdosn-nlp-hackathon-2023/names_bn.txt') as file:\n    lines = [x.strip() for x in file.readlines()]\n    for l in lines:\n        names_bn[l] = 1 ","metadata":{"execution":{"iopub.status.busy":"2023-01-21T10:07:32.252095Z","iopub.execute_input":"2023-01-21T10:07:32.252903Z","iopub.status.idle":"2023-01-21T10:07:32.312518Z","shell.execute_reply.started":"2023-01-21T10:07:32.252852Z","shell.execute_reply":"2023-01-21T10:07:32.311351Z"},"trusted":true},"execution_count":224,"outputs":[]},{"cell_type":"code","source":"## feature extraction for Conditional Random Field - Bangla NER\n## feature extraction for Conditional Random Field - Bangla NER\n\ndef wordToFeatures(sent, idx):\n    word = sent[idx][0]\n    postag = sent[idx][1]\n    \n    cluster_id = kmeans.predict([w2v.get_vector(word)])[0]\n    features = {\n        'bias': 1.0,\n        'word': word,\n        'cluster_id': cluster_id,\n        'word[-3:]': word[-3:],\n        'word[-2:]': word[-2:],\n        'word[:3]': word[:3],\n        'word[:2]': word[:2],\n        'word.isdigit': word.isdigit(),\n        'index': idx,\n        'length': len(word),\n        'postag': postag,\n        'freq': word_freq[word] if word in word_freq else 0,\n#         'is_name': int(word in names_bn), \n#         'movie_name': int(word in movies_bn),\n#         'album_name': int(word in album_names_bn),\n    }\n    \n#     if idx > 0:\n#         sub = sent[idx-1][0] + \" \"+ sent[idx][0]\n#         if sub in movies_bn:\n#             features['movie_name'] = 2\n#         if sub in album_names_bn:\n#             features['album_name'] = 2\n    \n#     if idx < len(sent) - 1:\n#         sub = sent[idx][0] + \" \"+ sent[idx+1][0]\n#         if sub in movies_bn:\n#             features['movie_name'] = 2\n#         if sub in album_names_bn:\n#             features['album_name'] = 2\n    \n#     if idx > 1:\n#         sub = sent[idx-2][0] + \" \"+ sent[idx-1][0] + \" \" + sent[idx][0]\n#         if sub in movies_bn:\n#             features['movie_name'] = 3\n#         if sub in album_names_bn:\n#             features['album_name'] = 3\n#     if idx < len(sent) - 2:\n#         sub = sent[idx][0] + \" \"+ sent[idx+1][0] + \" \" + sent[idx+2][0]\n#         if sub in movies_bn:\n#             features['movie_name'] = 3\n#         if sub in album_names_bn:\n#             features['album_name'] = 3\n        \n    \n        \n    \n    for i in range(1, 3):\n        if idx < i:\n            break\n        wordi = sent[idx-i][0]\n        postagi = sent[idx-i][1]\n        cluster_id_i = kmeans.predict([w2v.get_vector(wordi)])[0]\n        features.update({\n            '-{}:word'.format(i): wordi,\n            '-{}:cluster_id'.format(i): cluster_id_i,\n            '-{}:word[-3:]'.format(i): wordi[-3:],\n            '-{}:word[-2:]'.format(i): wordi[-2:],\n            '-{}:word[:3]'.format(i): wordi[:3],\n            '-{}:word[:2]'.format(i): wordi[:2],\n            '-{}:word.isdigit'.format(i): wordi.isdigit(),\n            '-{}:postag'.format(i): postagi,\n#             '-{}:is_name'.format(i) : int(wordi in names_bn)\n        })\n    \n    for i in range(1, 3):\n        if (idx+i) >= len(sent):\n            break\n        wordi = sent[idx+i][0]\n        postagi = sent[idx+i][1]\n        cluster_id_i = kmeans.predict([w2v.get_vector(wordi)])[0]\n        features.update({\n            '{}:word'.format(i): wordi,\n            '{}:cluster_id'.format(i): cluster_id_i,\n            '{}:word[-3:]'.format(i): wordi[-3:],\n            '{}:word[-2:]'.format(i): wordi[-2:],\n            '{}:word[:3]'.format(i): wordi[:3],\n            '{}:word[:2]'.format(i): wordi[:2],\n            '{}:word.isdigit'.format(i): wordi.isdigit(),\n            '{}:postag'.format(i): postagi,\n#             '{}:is_name'.format(i) : int(wordi in names_bn)\n        })\n        \n    if idx == 0:\n        features['BOS'] = True\n    if idx == len(sent) - 1:\n        features['EOS'] = True\n    \n    return features\n\ndef sentTofeatures(sent):\n    return [wordToFeatures(sent, i) for i in range(len(sent))]\n\ndef sentTolabels(sent):\n    return [label for token, postag, label in sent]","metadata":{"execution":{"iopub.status.busy":"2023-01-21T10:07:32.314116Z","iopub.execute_input":"2023-01-21T10:07:32.314484Z","iopub.status.idle":"2023-01-21T10:07:32.333365Z","shell.execute_reply.started":"2023-01-21T10:07:32.314453Z","shell.execute_reply":"2023-01-21T10:07:32.332181Z"},"trusted":true},"execution_count":225,"outputs":[]},{"cell_type":"code","source":"train_sents[0]","metadata":{"execution":{"iopub.status.busy":"2023-01-21T10:07:32.334711Z","iopub.execute_input":"2023-01-21T10:07:32.335132Z","iopub.status.idle":"2023-01-21T10:07:32.355513Z","shell.execute_reply.started":"2023-01-21T10:07:32.335097Z","shell.execute_reply":"2023-01-21T10:07:32.354223Z"},"trusted":true},"execution_count":226,"outputs":[{"execution_count":226,"output_type":"execute_result","data":{"text/plain":"[('তার', 'PPR', 'O'),\n ('মৃত্যুর', 'NC', 'O'),\n ('দশ', 'JQ', 'O'),\n ('দিন', 'NC', 'O'),\n ('পর,', 'NC', 'O'),\n ('১১৫', 'RDF', 'O'),\n ('কৃষ্ণাঙ্গ', 'NC', 'O'),\n ('উচ্চ', 'JJ', 'O'),\n ('বিদ্যালয়ের', 'NC', 'O'),\n ('শিক্ষার্থীরা', 'NC', 'O'),\n ('তার', 'PPR', 'O'),\n ('হত্যার', 'NC', 'O'),\n ('প্রতিবাদে', 'NC', 'O'),\n ('ম্যাককম্ব', 'NC', 'B-LOC'),\n ('এর', 'PPR', 'O'),\n ('মাধ্যমে', 'PP', 'O'),\n ('মিছিল', 'NC', 'O'),\n ('করেছে।', 'VM', 'O')]"},"metadata":{}}]},{"cell_type":"code","source":"%%time\nX_train = [sentTofeatures(s) for s in train_sents]\ny_train = [sentTolabels(s) for s in train_sents]","metadata":{"execution":{"iopub.status.busy":"2023-01-21T10:07:32.357828Z","iopub.execute_input":"2023-01-21T10:07:32.358168Z","iopub.status.idle":"2023-01-21T10:15:44.028619Z","shell.execute_reply.started":"2023-01-21T10:07:32.358140Z","shell.execute_reply":"2023-01-21T10:15:44.027145Z"},"trusted":true},"execution_count":227,"outputs":[{"name":"stdout","text":"CPU times: user 31min 55s, sys: 10.2 s, total: 32min 5s\nWall time: 8min 11s\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train[0][3]","metadata":{"execution":{"iopub.status.busy":"2023-01-21T10:15:44.030100Z","iopub.execute_input":"2023-01-21T10:15:44.030485Z","iopub.status.idle":"2023-01-21T10:15:44.040116Z","shell.execute_reply.started":"2023-01-21T10:15:44.030450Z","shell.execute_reply":"2023-01-21T10:15:44.038718Z"},"trusted":true},"execution_count":228,"outputs":[{"execution_count":228,"output_type":"execute_result","data":{"text/plain":"{'bias': 1.0,\n 'word': 'দিন',\n 'cluster_id': 472,\n 'word[-3:]': 'দিন',\n 'word[-2:]': 'িন',\n 'word[:3]': 'দিন',\n 'word[:2]': 'দি',\n 'word.isdigit': False,\n 'index': 3,\n 'length': 3,\n 'postag': 'NC',\n 'freq': 56,\n '-1:word': 'দশ',\n '-1:cluster_id': 320,\n '-1:word[-3:]': 'দশ',\n '-1:word[-2:]': 'দশ',\n '-1:word[:3]': 'দশ',\n '-1:word[:2]': 'দশ',\n '-1:word.isdigit': False,\n '-1:postag': 'JQ',\n '-2:word': 'মৃত্যুর',\n '-2:cluster_id': 63,\n '-2:word[-3:]': 'যুর',\n '-2:word[-2:]': 'ুর',\n '-2:word[:3]': 'মৃত',\n '-2:word[:2]': 'মৃ',\n '-2:word.isdigit': False,\n '-2:postag': 'NC',\n '1:word': 'পর,',\n '1:cluster_id': 190,\n '1:word[-3:]': 'পর,',\n '1:word[-2:]': 'র,',\n '1:word[:3]': 'পর,',\n '1:word[:2]': 'পর',\n '1:word.isdigit': False,\n '1:postag': 'NC',\n '2:word': '১১৫',\n '2:cluster_id': 305,\n '2:word[-3:]': '১১৫',\n '2:word[-2:]': '১৫',\n '2:word[:3]': '১১৫',\n '2:word[:2]': '১১',\n '2:word.isdigit': True,\n '2:postag': 'RDF'}"},"metadata":{}}]},{"cell_type":"code","source":"# y_train","metadata":{"execution":{"iopub.status.busy":"2023-01-21T10:15:44.042217Z","iopub.execute_input":"2023-01-21T10:15:44.043158Z","iopub.status.idle":"2023-01-21T10:15:44.052174Z","shell.execute_reply.started":"2023-01-21T10:15:44.043109Z","shell.execute_reply":"2023-01-21T10:15:44.050905Z"},"trusted":true},"execution_count":229,"outputs":[]},{"cell_type":"code","source":"%%time\nX_dev = [sentTofeatures(s) for s in dev_sents]\ny_dev = [sentTolabels(s) for s in dev_sents]","metadata":{"execution":{"iopub.status.busy":"2023-01-21T10:15:44.053734Z","iopub.execute_input":"2023-01-21T10:15:44.054108Z","iopub.status.idle":"2023-01-21T10:16:10.415647Z","shell.execute_reply.started":"2023-01-21T10:15:44.054075Z","shell.execute_reply":"2023-01-21T10:16:10.414658Z"},"trusted":true},"execution_count":230,"outputs":[{"name":"stdout","text":"CPU times: user 1min 43s, sys: 362 ms, total: 1min 43s\nWall time: 26.3 s\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train[0][3]","metadata":{"execution":{"iopub.status.busy":"2023-01-21T10:16:10.417050Z","iopub.execute_input":"2023-01-21T10:16:10.417758Z","iopub.status.idle":"2023-01-21T10:16:10.427356Z","shell.execute_reply.started":"2023-01-21T10:16:10.417715Z","shell.execute_reply":"2023-01-21T10:16:10.426001Z"},"trusted":true},"execution_count":231,"outputs":[{"execution_count":231,"output_type":"execute_result","data":{"text/plain":"{'bias': 1.0,\n 'word': 'দিন',\n 'cluster_id': 472,\n 'word[-3:]': 'দিন',\n 'word[-2:]': 'িন',\n 'word[:3]': 'দিন',\n 'word[:2]': 'দি',\n 'word.isdigit': False,\n 'index': 3,\n 'length': 3,\n 'postag': 'NC',\n 'freq': 56,\n '-1:word': 'দশ',\n '-1:cluster_id': 320,\n '-1:word[-3:]': 'দশ',\n '-1:word[-2:]': 'দশ',\n '-1:word[:3]': 'দশ',\n '-1:word[:2]': 'দশ',\n '-1:word.isdigit': False,\n '-1:postag': 'JQ',\n '-2:word': 'মৃত্যুর',\n '-2:cluster_id': 63,\n '-2:word[-3:]': 'যুর',\n '-2:word[-2:]': 'ুর',\n '-2:word[:3]': 'মৃত',\n '-2:word[:2]': 'মৃ',\n '-2:word.isdigit': False,\n '-2:postag': 'NC',\n '1:word': 'পর,',\n '1:cluster_id': 190,\n '1:word[-3:]': 'পর,',\n '1:word[-2:]': 'র,',\n '1:word[:3]': 'পর,',\n '1:word[:2]': 'পর',\n '1:word.isdigit': False,\n '1:postag': 'NC',\n '2:word': '১১৫',\n '2:cluster_id': 305,\n '2:word[-3:]': '১১৫',\n '2:word[-2:]': '১৫',\n '2:word[:3]': '১১৫',\n '2:word[:2]': '১১',\n '2:word.isdigit': True,\n '2:postag': 'RDF'}"},"metadata":{}}]},{"cell_type":"code","source":"X_dev[0][0]","metadata":{"execution":{"iopub.status.busy":"2023-01-21T10:16:10.429471Z","iopub.execute_input":"2023-01-21T10:16:10.429982Z","iopub.status.idle":"2023-01-21T10:16:10.442343Z","shell.execute_reply.started":"2023-01-21T10:16:10.429934Z","shell.execute_reply":"2023-01-21T10:16:10.440937Z"},"trusted":true},"execution_count":232,"outputs":[{"execution_count":232,"output_type":"execute_result","data":{"text/plain":"{'bias': 1.0,\n 'word': 'তিনি',\n 'cluster_id': 220,\n 'word[-3:]': 'িনি',\n 'word[-2:]': 'নি',\n 'word[:3]': 'তিন',\n 'word[:2]': 'তি',\n 'word.isdigit': False,\n 'index': 0,\n 'length': 4,\n 'postag': 'PPR',\n 'freq': 2822,\n '1:word': 'যুবক',\n '1:cluster_id': 98,\n '1:word[-3:]': 'ুবক',\n '1:word[-2:]': 'বক',\n '1:word[:3]': 'যুব',\n '1:word[:2]': 'যু',\n '1:word.isdigit': False,\n '1:postag': 'NC',\n '2:word': 'হিসেবে',\n '2:cluster_id': 120,\n '2:word[-3:]': 'েবে',\n '2:word[-2:]': 'বে',\n '2:word[:3]': 'হিস',\n '2:word[:2]': 'হি',\n '2:word.isdigit': False,\n '2:postag': 'PP',\n 'BOS': True}"},"metadata":{}}]},{"cell_type":"code","source":"import nltk\nimport sklearn\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.preprocessing import LabelBinarizer\nimport sklearn_crfsuite as crfsuite\nfrom sklearn_crfsuite import metrics","metadata":{"execution":{"iopub.status.busy":"2023-01-21T10:16:10.445559Z","iopub.execute_input":"2023-01-21T10:16:10.446266Z","iopub.status.idle":"2023-01-21T10:16:10.452966Z","shell.execute_reply.started":"2023-01-21T10:16:10.446213Z","shell.execute_reply":"2023-01-21T10:16:10.451860Z"},"trusted":true},"execution_count":233,"outputs":[]},{"cell_type":"code","source":"# crf = crfsuite.CRF(\n#     verbose='true',\n#     algorithm='lbfgs',\n#     max_iterations=100\n# )\n\n# crf.fit(X_train, y_train, X_dev=X_dev, y_dev=y_dev)","metadata":{"execution":{"iopub.status.busy":"2023-01-21T10:16:10.454451Z","iopub.execute_input":"2023-01-21T10:16:10.455326Z","iopub.status.idle":"2023-01-21T10:16:10.472630Z","shell.execute_reply.started":"2023-01-21T10:16:10.455283Z","shell.execute_reply":"2023-01-21T10:16:10.471070Z"},"trusted":true},"execution_count":234,"outputs":[]},{"cell_type":"code","source":"crf = crfsuite.CRF(\n    verbose='true',\n    algorithm='lbfgs',\n    c1=0.1,\n    c2=0.1,\n    max_iterations=150,\n    all_possible_transitions=True\n)\ntry:\n    crf.fit(X_train, y_train, X_dev=X_dev, y_dev=y_dev)\nexcept:\n    pass","metadata":{"execution":{"iopub.status.busy":"2023-01-21T10:16:10.474679Z","iopub.execute_input":"2023-01-21T10:16:10.475318Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"loading training data to CRFsuite: 100%|██████████| 15300/15300 [00:12<00:00, 1212.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"loading dev data to CRFsuite: 100%|██████████| 800/800 [00:01<00:00, 791.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nHoldout group: 2\n\nFeature generation\ntype: CRF1d\nfeature.minfreq: 0.000000\nfeature.possible_states: 0\nfeature.possible_transitions: 1\n0....1....2....3....4....5....6....7....8....9....10","output_type":"stream"}]},{"cell_type":"code","source":"# %%time\n# crf = crfsuite.CRF(\n#     algorithm='lbfgs',\n#     c1=0.1,\n#     c2=0.1,\n#     max_iterations=100,\n#     all_possible_transitions=True\n# )\n# crf.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = list(crf.classes_)\nlabels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = crf.predict(X_dev)\nmetrics.flat_f1_score(y_dev, y_pred,\n                      average='macro', labels=labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_test(filename):\n    with open(filename, 'r',encoding='utf-8') as f:\n        data = [line.strip() for line in f.readlines()]\n        \n        sentences = []\n        cur = []\n        for i, line in enumerate(data):\n            if line == '':\n                cur = [tuple([line, ' ']) for line in cur]\n                sentences.append(cur)\n                cur = []\n            else:\n                for p in punctuations:\n                    line = line.replace(p, '')\n                if len(line) == 0:\n                    line = ' '\n                cur.append(line)\n        # # convert each list to a tuple\n        sentences.append(cur)\n        return sentences","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = load_test('/kaggle/input/bdosn-nlp-hackathon-2023/test.txt')\nlen(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_sents =  add_pos_to_all(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = [sentTofeatures(s) for s in test_sents]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = crf.predict(X_test)\n# metrics.flat_f1_score(y_dev, y_pred,\n#                       average='macro', labels=labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"predictions_crf_with_kmeans_gazetteer.txt\", \"w\") as file:\n    for p in y_pred:\n        for l in p:\n            file.write(l +\"\\n\")\n        file.write(\"\\n\")\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}