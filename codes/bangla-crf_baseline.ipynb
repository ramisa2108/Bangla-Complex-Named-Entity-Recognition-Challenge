{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sbnltk\n!pip install simpletransformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-21T07:04:48.744753Z","iopub.execute_input":"2023-01-21T07:04:48.745228Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0mCollecting simpletransformers\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip uninstall scikit-learn -y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install scikit-learn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.mixture import GaussianMixture","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport string \n\npunctuations = list(string.punctuation) + ['।']\nprint(punctuations)","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:05:21.111279Z","iopub.execute_input":"2023-01-21T08:05:21.111703Z","iopub.status.idle":"2023-01-21T08:05:21.117898Z","shell.execute_reply.started":"2023-01-21T08:05:21.111670Z","shell.execute_reply":"2023-01-21T08:05:21.116582Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', '।']\n","output_type":"stream"}]},{"cell_type":"code","source":"def load_data(filename):\n    with open(filename, 'r',encoding='utf-8') as f:\n        data = [line.strip().split(' _ _ ') for line in f.readlines()]\n        # return data\n        # empty lines are used to separate sentences\n        # separate them into sentences\n        sentences = []\n        cur = []\n        for line in data:\n            if line == ['']:\n                cur = [tuple(line) for line in cur]\n                sentences.append(cur)\n                cur = []\n            else:\n                for p in punctuations:\n                    line[0] = line[0].replace(p, '')\n                if len(line[0]) == 0:\n                    line[0] = ' '\n                cur.append(line)\n        # # convert each list to a tuple\n        sentences.append(cur)\n        return sentences","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:04:53.452263Z","iopub.execute_input":"2023-01-21T08:04:53.452690Z","iopub.status.idle":"2023-01-21T08:04:53.461819Z","shell.execute_reply.started":"2023-01-21T08:04:53.452653Z","shell.execute_reply":"2023-01-21T08:04:53.460118Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def load_words(filename):\n    with open(filename, 'r',encoding='utf-8') as f:\n        data = [line.strip().split(' _ _ ') for line in f.readlines()]\n        words = []\n        for line in data:\n            if line == ['']:\n                continue\n            else:\n                words.append(line[0])\n        # # convert each list to a tuple\n        return list(set(words))","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:04:55.813096Z","iopub.execute_input":"2023-01-21T08:04:55.813805Z","iopub.status.idle":"2023-01-21T08:04:55.820306Z","shell.execute_reply.started":"2023-01-21T08:04:55.813767Z","shell.execute_reply":"2023-01-21T08:04:55.819122Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_words_set = load_words('/kaggle/input/bdosn-nlp-hackathon-2023/train.txt')\ndev_words_set = load_words('/kaggle/input/bdosn-nlp-hackathon-2023/dev.txt')","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:05:00.311208Z","iopub.execute_input":"2023-01-21T08:05:00.311635Z","iopub.status.idle":"2023-01-21T08:05:00.971487Z","shell.execute_reply.started":"2023-01-21T08:05:00.311587Z","shell.execute_reply":"2023-01-21T08:05:00.970361Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"len(dev_words_set), dev_words_set[:10]","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:05:03.020917Z","iopub.execute_input":"2023-01-21T08:05:03.021310Z","iopub.status.idle":"2023-01-21T08:05:03.032359Z","shell.execute_reply.started":"2023-01-21T08:05:03.021279Z","shell.execute_reply":"2023-01-21T08:05:03.030764Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(4713,\n ['হারমোনিকা',\n  'চেয়ারটি',\n  'উৎপাদিত',\n  'সম্পর্কে।',\n  'ভোকাল',\n  'বস্তুবাদে',\n  'পরেন।',\n  'রাজকীয়ভাবে',\n  'সুখী',\n  'রিজেনরন'])"},"metadata":{}}]},{"cell_type":"code","source":"import os\nos.listdir('/kaggle/input/bdosn-nlp-hackathon-2023/')","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:05:04.665622Z","iopub.execute_input":"2023-01-21T08:05:04.666035Z","iopub.status.idle":"2023-01-21T08:05:04.675877Z","shell.execute_reply.started":"2023-01-21T08:05:04.666003Z","shell.execute_reply":"2023-01-21T08:05:04.674824Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"['location.txt',\n 'album_names_bn.txt',\n 'location_names_bn.txt',\n 'names_bn.txt',\n 'gazetters',\n 'train.txt',\n 'dev.txt',\n 'location_small.txt',\n 'movies_bn.txt']"},"metadata":{}}]},{"cell_type":"code","source":"from sbnltk.word_embedding import gensim_word2vec_embedding\nw2v=gensim_word2vec_embedding()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_w2v(words):\n    ret = []\n    for word in words:\n        ret.append(w2v.get_vector(word))\n    return np.asarray(ret)\n\ndef get_cluster_id(words):\n    words_w2v = get_w2v(words)\n    kmeans = KMeans(n_clusters=500, random_state=0).fit(words_w2v)\n    return kmeans.labels_, kmeans","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_words_w2v = get_w2v(train_words_set)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dev_words_w2v = get_w2v(dev_words_set)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gmm = GaussianMixture(n_components=500, random_state=0).fit(train_words_w2v)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# kmeans = KMeans(n_clusters=500, random_state=0).fit(train_words_w2v)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# kmeans.labels_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# kmeans.predict(train_words_w2v[0:2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gmm.predict(train_words_w2v[0:2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = load_data('/kaggle/input/bdosn-nlp-hackathon-2023/train.txt')","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:05:25.684419Z","iopub.execute_input":"2023-01-21T08:05:25.684848Z","iopub.status.idle":"2023-01-21T08:05:27.881936Z","shell.execute_reply.started":"2023-01-21T08:05:25.684814Z","shell.execute_reply":"2023-01-21T08:05:27.880560Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"dev = load_data('/kaggle/input/bdosn-nlp-hackathon-2023/dev.txt')","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:05:28.494762Z","iopub.execute_input":"2023-01-21T08:05:28.495177Z","iopub.status.idle":"2023-01-21T08:05:28.593972Z","shell.execute_reply.started":"2023-01-21T08:05:28.495145Z","shell.execute_reply":"2023-01-21T08:05:28.592738Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"dev[6]\n","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:05:32.276771Z","iopub.execute_input":"2023-01-21T08:05:32.277208Z","iopub.status.idle":"2023-01-21T08:05:32.286073Z","shell.execute_reply.started":"2023-01-21T08:05:32.277172Z","shell.execute_reply":"2023-01-21T08:05:32.284646Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"[('আরিয়ানা', 'B-PER'),\n ('গ্রান্দে', 'I-PER'),\n (' ', 'O'),\n ('লিড', 'O'),\n ('ভোকাল', 'O'),\n ('ব্যাকগ্রাউন্ড', 'O'),\n ('ভোকাল', 'O'),\n ('গান', 'O'),\n ('রচনা', 'O'),\n ('ভোকাল', 'O'),\n ('প্রোডাকশন', 'O'),\n ('ভোকাল', 'O'),\n ('অ্যারেঞ্জমেন্ট', 'O'),\n ('অডিও', 'O'),\n ('ইঞ্জিনিয়ারিং', 'O')]"},"metadata":{}}]},{"cell_type":"code","source":"train[0]","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:05:34.377165Z","iopub.execute_input":"2023-01-21T08:05:34.377904Z","iopub.status.idle":"2023-01-21T08:05:34.386129Z","shell.execute_reply.started":"2023-01-21T08:05:34.377867Z","shell.execute_reply":"2023-01-21T08:05:34.384848Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"[('তার', 'O'),\n ('মৃত্যুর', 'O'),\n ('দশ', 'O'),\n ('দিন', 'O'),\n ('পর', 'O'),\n ('১১৫', 'O'),\n ('কৃষ্ণাঙ্গ', 'O'),\n ('উচ্চ', 'O'),\n ('বিদ্যালয়ের', 'O'),\n ('শিক্ষার্থীরা', 'O'),\n ('তার', 'O'),\n ('হত্যার', 'O'),\n ('প্রতিবাদে', 'O'),\n ('ম্যাককম্ব', 'B-LOC'),\n ('এর', 'O'),\n ('মাধ্যমে', 'O'),\n ('মিছিল', 'O'),\n ('করেছে', 'O')]"},"metadata":{}}]},{"cell_type":"code","source":"!pip install bnlp_toolkit\n","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:05:37.032296Z","iopub.execute_input":"2023-01-21T08:05:37.032711Z","iopub.status.idle":"2023-01-21T08:05:48.376947Z","shell.execute_reply.started":"2023-01-21T08:05:37.032677Z","shell.execute_reply":"2023-01-21T08:05:48.375676Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Requirement already satisfied: bnlp_toolkit in /opt/conda/lib/python3.7/site-packages (3.2.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from bnlp_toolkit) (3.8.1)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from bnlp_toolkit) (1.7.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from bnlp_toolkit) (4.64.0)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from bnlp_toolkit) (0.1.97)\nRequirement already satisfied: sklearn-crfsuite in /opt/conda/lib/python3.7/site-packages (from bnlp_toolkit) (0.3.6)\nRequirement already satisfied: gensim==4.0.1 in /opt/conda/lib/python3.7/site-packages (from bnlp_toolkit) (4.0.1)\nRequirement already satisfied: wasabi in /opt/conda/lib/python3.7/site-packages (from bnlp_toolkit) (0.10.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from bnlp_toolkit) (1.21.6)\nRequirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim==4.0.1->bnlp_toolkit) (6.3.0)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk->bnlp_toolkit) (2021.11.10)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk->bnlp_toolkit) (1.0.1)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk->bnlp_toolkit) (8.1.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sklearn-crfsuite->bnlp_toolkit) (1.15.0)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from sklearn-crfsuite->bnlp_toolkit) (0.9.0)\nRequirement already satisfied: python-crfsuite>=0.8.3 in /opt/conda/lib/python3.7/site-packages (from sklearn-crfsuite->bnlp_toolkit) (0.9.8)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->nltk->bnlp_toolkit) (4.13.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk->bnlp_toolkit) (3.8.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk->bnlp_toolkit) (4.1.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/sagorbrur/bnlp","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:05:48.379531Z","iopub.execute_input":"2023-01-21T08:05:48.380072Z","iopub.status.idle":"2023-01-21T08:05:49.474885Z","shell.execute_reply.started":"2023-01-21T08:05:48.380030Z","shell.execute_reply":"2023-01-21T08:05:49.473555Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"fatal: destination path 'bnlp' already exists and is not an empty directory.\n","output_type":"stream"}]},{"cell_type":"code","source":"from bnlp import POS\nbn_pos = POS()\nmodel_path = \"/kaggle/working/bnlp/model/bn_pos.pkl\"\ntext = \"আমি ভাত খাই।\" # or you can pass ['আমি', 'ভাত', 'খাই', '।']\nres = bn_pos.tag(model_path, text)\nprint(res)\n# [('আমি', 'PPR'), ('ভাত', 'NC'), ('খাই', 'VM'), ('।', 'PU')]","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:05:49.476578Z","iopub.execute_input":"2023-01-21T08:05:49.477006Z","iopub.status.idle":"2023-01-21T08:05:49.518216Z","shell.execute_reply.started":"2023-01-21T08:05:49.476968Z","shell.execute_reply":"2023-01-21T08:05:49.517010Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"[('আমি', 'PPR'), ('ভাত', 'NC'), ('খাই', 'VM'), ('।', 'PU')]\n","output_type":"stream"}]},{"cell_type":"code","source":"def add_pos(sentence):\n    # first one of the tuple is the word and the second one is the ner  \n    words = []\n    for word in sentence:\n        words.append(word[0])\n    pos = bn_pos.tag(model_path, words)\n    ## add ner back to the tuple\n    ret = []\n    for i in range(len(pos)):\n        word = sentence[i][0]\n        ner = sentence[i][1]\n        ret.append((word, pos[i][1], ner))\n    return ret\n\ndef add_pos_to_all(sents):\n    ret = []\n    for i in range(len(sents)):\n        if i % 100 == 0:\n            print(i)\n        ret.append(add_pos(sents[i]))\n    return ret","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:05:49.521137Z","iopub.execute_input":"2023-01-21T08:05:49.521478Z","iopub.status.idle":"2023-01-21T08:05:49.530905Z","shell.execute_reply.started":"2023-01-21T08:05:49.521450Z","shell.execute_reply":"2023-01-21T08:05:49.529509Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"add_pos(train[0])","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:05:53.121378Z","iopub.execute_input":"2023-01-21T08:05:53.121870Z","iopub.status.idle":"2023-01-21T08:05:53.165325Z","shell.execute_reply.started":"2023-01-21T08:05:53.121830Z","shell.execute_reply":"2023-01-21T08:05:53.164112Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"[('তার', 'PPR', 'O'),\n ('মৃত্যুর', 'NC', 'O'),\n ('দশ', 'JQ', 'O'),\n ('দিন', 'NC', 'O'),\n ('পর', 'NST', 'O'),\n ('১১৫', 'RDF', 'O'),\n ('কৃষ্ণাঙ্গ', 'NC', 'O'),\n ('উচ্চ', 'JJ', 'O'),\n ('বিদ্যালয়ের', 'NC', 'O'),\n ('শিক্ষার্থীরা', 'NC', 'O'),\n ('তার', 'PPR', 'O'),\n ('হত্যার', 'NC', 'O'),\n ('প্রতিবাদে', 'NC', 'O'),\n ('ম্যাককম্ব', 'NC', 'B-LOC'),\n ('এর', 'PPR', 'O'),\n ('মাধ্যমে', 'PP', 'O'),\n ('মিছিল', 'NC', 'O'),\n ('করেছে', 'VM', 'O')]"},"metadata":{}}]},{"cell_type":"code","source":"train_sents =  add_pos_to_all(train)","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:06:37.296138Z","iopub.execute_input":"2023-01-21T08:06:37.296753Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"0\n100\n200\n300\n400\n500\n600\n700\n800\n900\n1000\n1100\n1200\n1300\n1400\n1500\n1600\n1700\n1800\n1900\n2000\n2100\n2200\n2300\n2400\n2500\n2600\n2700\n2800\n2900\n3000\n3100\n3200\n3300\n3400\n3500\n3600\n3700\n3800\n3900\n4000\n4100\n4200\n4300\n4400\n4500\n4600\n4700\n4800\n4900\n5000\n5100\n5200\n5300\n5400\n5500\n5600\n5700\n5800\n5900\n6000\n6100\n6200\n6300\n6400\n6500\n6600\n6700\n6800\n6900\n7000\n7100\n7200\n7300\n7400\n7500\n7600\n7700\n7800\n7900\n8000\n8100\n8200\n8300\n8400\n8500\n8600\n8700\n8800\n8900\n9000\n9100\n9200\n9300\n9400\n9500\n9600\n9700\n9800\n9900\n10000\n10100\n10200\n10300\n10400\n10500\n10600\n10700\n10800\n10900\n11000\n11100\n11200\n11300\n11400\n11500\n11600\n11700\n11800\n11900\n12000\n12100\n12200\n12300\n12400\n12500\n12600\n12700\n12800\n12900\n13000\n13100\n13200\n13300\n13400\n13500\n13600\n13700\n13800\n13900\n14000\n14100\n14200\n","output_type":"stream"}]},{"cell_type":"code","source":"dev_sents = add_pos_to_all(dev)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_sents[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dev_sents[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip3 install tensorflow-hub","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_all_words(sents):\n    words = []\n    for i in range(len(sents)):\n        for w in sents[i]:\n            words += [w[0]]\n    return words","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_train_words = get_all_words(train_sents)\nlen(all_train_words)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_freq = {}\nfor w in all_train_words:\n    if w in word_freq:\n        word_freq[w] += 1\n    else:\n        word_freq[w] = 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the Gazetters\n\nalbum_names_bn = {}\nmovies_bn = {}\nnames_bn = {}\nlocations_bn = {}\n\nwith open('/kaggle/input/bdosn-nlp-hackathon-2023/album_names_bn.txt') as file:\n    lines = [x.strip() for x in file.readlines()]\n    for l in lines:\n        album_names_bn[l] = 1\n        words = l.split()\n        for size in range(2, 4, 1):\n            for i in range(len(words)):\n                if (i + size) >= len(words):\n                    break\n                album_names_bn[\" \".join(words[i: i+size])] = 1\n\nwith open('/kaggle/input/bdosn-nlp-hackathon-2023/movies_bn.txt') as file:\n    lines = [x.strip() for x in file.readlines()]\n    for l in lines:\n        movies_bn[l] = 1\n        words = l.split()\n        for size in range(2, 4, 1):\n            for i in range(len(words)):\n                if (i + size) > len(words):\n                    break\n                movies_bn[\" \".join(words[i: i+size])] = 1\n\nwith open('/kaggle/input/bdosn-nlp-hackathon-2023/location_names_bn.txt') as file:\n    lines = [x.strip() for x in file.readlines()]\n    for l in lines:\n        locations_bn[l] = 1\n        words = l.split()\n        for size in range(2, 4, 1):\n            for i in range(len(words)):\n                if (i + size) >= len(words):\n                    break\n                locations_bn[\" \".join(words[i: i+size])] = 1\n\n\nwith open('/kaggle/input/bdosn-nlp-hackathon-2023/names_bn.txt') as file:\n    lines = [x.strip() for x in file.readlines()]\n    for l in lines:\n        names_bn[l] = 1 ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## feature extraction for Conditional Random Field - Bangla NER\n## feature extraction for Conditional Random Field - Bangla NER\n\ndef wordToFeatures(sent, idx):\n    word = sent[idx][0]\n    postag = sent[idx][1]\n    \n#     cluster_id = kmeans.predict([w2v.get_vector(word)])[0]\n    features = {\n        'bias': 1.0,\n        'word': word,\n#         'cluster_id': cluster_id,\n        'word[-3:]': word[-3:],\n        'word[-2:]': word[-2:],\n        'word[:3]': word[:3],\n        'word[:2]': word[:2],\n        'word.isdigit': word.isdigit(),\n        'index': idx,\n        'length': len(word),\n        'postag': postag,\n        'freq': word_freq[word] if word in word_freq else 0,\n        'is_name': int(word in names_bn), \n        'movie_name': int(word in movies_bn),\n        'album_name': int(word in album_names_bn),\n    }\n    \n    if idx > 0:\n        sub = sent[idx-1][0] + \" \"+ sent[idx][0]\n        if sub in movies_bn:\n            features['movie_name'] = 2\n        if sub in album_names_bn:\n            features['album_name'] = 2\n    \n    if idx < len(sent) - 1:\n        sub = sent[idx][0] + \" \"+ sent[idx+1][0]\n        if sub in movies_bn:\n            features['movie_name'] = 2\n        if sub in album_names_bn:\n            features['album_name'] = 2\n    \n    if idx > 1:\n        sub = sent[idx-2][0] + \" \"+ sent[idx-1][0] + \" \" + sent[idx][0]\n        if sub in movies_bn:\n            features['movie_name'] = 3\n        if sub in album_names_bn:\n            features['album_name'] = 3\n    if idx < len(sent) - 2:\n        sub = sent[idx][0] + \" \"+ sent[idx+1][0] + \" \" + sent[idx+2][0]\n        if sub in movies_bn:\n            features['movie_name'] = 3\n        if sub in album_names_bn:\n            features['album_name'] = 3\n        \n    \n        \n    \n    for i in range(1, 3):\n        if idx < i:\n            break\n        wordi = sent[idx-i][0]\n        postagi = sent[idx-i][1]\n#         cluster_id_i = kmeans.predict([w2v.get_vector(wordi)])[0]\n        features.update({\n            '-{}:word'.format(i): wordi,\n#             '-{}:cluster_id'.format(i): cluster_id_i,\n            '-{}:word[-3:]'.format(i): wordi[-3:],\n            '-{}:word[-2:]'.format(i): wordi[-2:],\n            '-{}:word[:3]'.format(i): wordi[:3],\n            '-{}:word[:2]'.format(i): wordi[:2],\n            '-{}:word.isdigit'.format(i): wordi.isdigit(),\n            '-{}:postag'.format(i): postagi,\n            '-{}:is_name'.format(i) : int(wordi in names_bn)\n        })\n    \n    for i in range(1, 3):\n        if (idx+i) >= len(sent):\n            break\n        wordi = sent[idx+i][0]\n        postagi = sent[idx+i][1]\n#         cluster_id_i = kmeans.predict([w2v.get_vector(wordi)])[0]\n        features.update({\n            '{}:word'.format(i): wordi,\n#             '{}:cluster_id'.format(i): cluster_id_i,\n            '{}:word[-3:]'.format(i): wordi[-3:],\n            '{}:word[-2:]'.format(i): wordi[-2:],\n            '{}:word[:3]'.format(i): wordi[:3],\n            '{}:word[:2]'.format(i): wordi[:2],\n            '{}:word.isdigit'.format(i): wordi.isdigit(),\n            '{}:postag'.format(i): postagi,\n            '{}:is_name'.format(i) : int(wordi in names_bn)\n        })\n        \n    if idx == 0:\n        features['BOS'] = True\n    if idx == len(sent) - 1:\n        features['EOS'] = True\n    \n    return features\n\ndef sentTofeatures(sent):\n    return [wordToFeatures(sent, i) for i in range(len(sent))]\n\ndef sentTolabels(sent):\n    return [label for token, postag, label in sent]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_sents[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nX_train = [sentTofeatures(s) for s in train_sents]\ny_train = [sentTolabels(s) for s in train_sents]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train[0][3]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nX_dev = [sentTofeatures(s) for s in dev_sents]\ny_dev = [sentTolabels(s) for s in dev_sents]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train[0][3]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_dev[0][0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nimport sklearn\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.preprocessing import LabelBinarizer\nimport sklearn_crfsuite as crfsuite\nfrom sklearn_crfsuite import metrics","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# crf = crfsuite.CRF(\n#     verbose='true',\n#     algorithm='lbfgs',\n#     max_iterations=100\n# )\n\n# crf.fit(X_train, y_train, X_dev=X_dev, y_dev=y_dev)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"crf = crfsuite.CRF(\n    verbose='true',\n    algorithm='lbfgs',\n    c1=0.1,\n    c2=0.1,\n    max_iterations=100,\n    all_possible_transitions=True\n)\ntry:\n    crf.fit(X_train, y_train, X_dev=X_dev, y_dev=y_dev)\nexcept:\n    pass","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%time\n# crf = crfsuite.CRF(\n#     algorithm='lbfgs',\n#     c1=0.1,\n#     c2=0.1,\n#     max_iterations=100,\n#     all_possible_transitions=True\n# )\n# crf.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = list(crf.classes_)\nlabels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = crf.predict(X_dev)\nmetrics.flat_f1_score(y_dev, y_pred,\n                      average='macro', labels=labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check for inconsistency in B and I type tags\nfor i in range(len(y_pred)):\n    for j in range(1, len(y_pred[i]), 1):\n        s = y_pred[i][j][0]\n        if s=='I':\n            if y_pred[i][j][1:] != y_pred[i][j-1][1:]:\n                print(i, j, y_pred[i][j-1], y_pred[i][j])\n            elif y_pred[i][j-1][0] != 'B' and y_pred[i][j-1][0] != 'I':\n                print(i, j, y_pred[i][j-1], y_pred[i][j])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_test(filename):\n    with open(filename, 'r',encoding='utf-8') as f:\n        data = [line.strip() for line in f.readlines()]\n        # return data\n        # empty lines are used to separate sentences\n        # separate them into sentences\n        sentences = []\n        cur = []\n        for line in data:\n            if line == ['']:\n                sentences.append(cur)\n                cur = []\n            else:\n                for p in punctuations:\n                    line = line.replace(p, '')\n                if len(line) == 0:\n                    line = ' '\n                cur.append(line)\n        # # convert each list to a tuple\n        sentences.append(cur)\n        return sentences","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = load_data('/kaggle/input/bdosn-nlp-hackathon-2023/test.txt')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_sents =  add_pos_to_all(test)\n\nX_test = [sentTofeatures(s) for s in test_sents]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = crf.predict(X_test)\n# metrics.flat_f1_score(y_dev, y_pred,\n#                       average='macro', labels=labels)","metadata":{},"execution_count":null,"outputs":[]}]}